{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning For Everyone\n",
    "Lecture notes for HuStar Project by idebtor@gmail.com \n",
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 1 강: 함수와 뉴론$^{Function \\ and \\ Neuron}$ (1/2)\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "- 함수와 뉴론을 이해한다.\n",
    "- 인공뉴론과 인공신경망을 이해한다. \n",
    "- 첫 인공뉴론을 구현한다. \n",
    "\n",
    "## 학습 내용\n",
    "\n",
    "- 함수와 뉴론\n",
    "- 인공뉴론과 인공신경망\n",
    "- 인공뉴론의 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 함수\n",
    "\n",
    "이 강의를 듣는 모든 수강생은 함수에 대해 공부한 적이 있습니다. 저는 중학교 때 처음으로 \"함수\"라는 단어를 처음 접했을텐데, '함수가 뭐지, 참 어렵다'고 생각했던 것만 기억이 납니다. 지금 생각하면 어려운 것도 아닌데 힘들었던 모양입니다. 아직도 조금은 기억이 나니까 말입니다. \n",
    "\n",
    "그런데, 함수가 도대체 뭐죠?  \n",
    "수학적으로 정의하지 말고, 가볍게 생각하면, 함수에는 입력 x가 있고, 출력 y가 있습니다. 입력을 독립변수, 출력을 종속변수라 볼 수 있습니다. 입력 x의 값이 변함에 따라 출력 y의 값이 달라지는 관계입니다. 이 때, x와 y의 관계를 나타내는 식이 __함수__ 입니다. \n",
    "\n",
    "다음 그림은 함수 $y = f(x)$를 표현한 것입니다. 즉 함수 $f$는 입력 $x$를 받아 $y$를 출력합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/function_f_x.png?raw=true\" width=\"400\">\n",
    "<center>그림 2: 함수 $y = f(x)$의 모형</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면, 섭씨 온도를 화씨로 변환하는 함수는 다음과 같이 정의할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/c_to_f.png?raw=true\" width=\"400\">\n",
    "<center>그림 3: 온도변환 함수 $y = f(x)$의 모형</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과학자들은 다양한 자연 현상이나 우리가 필요한 것마다 수학적으로 모델링하여 __함수__를 정의해왔습니다. \n",
    "\n",
    "예를 들면, 현대통신의 시작과 끝이라고 말할 정도로 광범위하게 쓰이는 프리에$^{Fourier}$ 변환도 다음과 같은 __함수__에 의해 이루어집니다. 푸리에 함수는 시간의 대한 입력 값을 받아 주파수 영역의 값으로 변환할 수 있는 함수입니다. 이 함수 덕분에 우리가 방송을 하고 휴대폰으로 전화를 할 수 있는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    " f(x) &= \\sum_{n=-\\infty}^{\\infty}c_n e^{2 \\pi i\\left(\\frac{n}{T}\\right)x} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 영상이나 이미지를 휴대전화에서도 다룰 수 있는 것은 분량이 큰 이미지나 영상을 압축해서 작은 크기로 변환하고, 다시 복원할 수 있는 함수를 만들어낼 수 있어서 가능한 것입니다. 과학자들이 그런 작용을 할 수 있는 아래와 같은 코사인$^{cosine}$ 변환이라는 함수를 찾아낸 것입니다. \n",
    "\n",
    "\\begin{align}\n",
    " F(u,v) &= \\left(\\frac{2}{N}\\right)^{\\frac{1}{2}} \\left(\\frac{2}{M}\\right)^{\\frac{1}{2}}\n",
    "           \\sum_{i=0}^{N-1}\\sum_{j=0}^{M-1} f(i,j) \n",
    "           cos\\left[\\frac{\\pi(2i + 1)u}{2N}\\right] \n",
    "           cos\\left[\\frac{\\pi(2j + 1)v}{2M}\\right]\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 복잡한 함수도 찾아내서 이미지나 영상을 압축해서 우리가 오늘 사용하고 있습니다. \n",
    "\n",
    "그러나 최근 기계학습이나 딥러닝이 나오기까지 과학자들이 만들어내지 못했던 함수들 중에 하나는 많은 사진이나 동영상에서 고양이를 찾아내는 것입니다. 너무나도 다양한 경우의 수가 있기 때문에 이를 만족하는 __함수__ 를 작성하기 매우 힘들었지요. 사진들을 입력으로 받아 사람이 울고 있는지 웃고 있는지 구별하는 함수조차 만들 수 없었습니다. \n",
    "\n",
    "물론, 한 때는 스탠포드 연구팀의 기계학습에서는 이 사진을 보고 어린 아이가 야구방망이를 잡고 있다고 했지만, 이제는 사람이 직접 찾아내는 것만큼 컴퓨터가 고양이를 찾아낼 수 있고, 사람이 웃고 있는지 울고 있는지 구별해낼 수도 있습니다. 기계학습/딥러닝 덕분이죠. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터가 이런 일을 할 수 있도록 하기 위한 전제 조건은 무엇인가요?  Data, Big Data가 문제입니다. \n",
    "\n",
    "자료가 많아야 한다는 것입니다. 그래서, 이제는 세계적인 IT회사들이 경쟁적으로 수십 기가바이트 용량의 저장공간을 우리들에게 무료로 제공하면서 데이터를 올리라고 권하는 것입니다. \n",
    "\n",
    "결론적으로 제가 개인적으로 만들어 낸 \"기계학습의 정의\"는 __Universal Function Generator__, 우리 말로 하면 __만능 함수 제조기__ 혹은 __꿈의 함수 제조기__$^{dream \\ function \\ generator}$ 라고 부르고 싶습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/universal_function_generator.png?raw=true\" width=\"600\">\n",
    "<center>그림 4: 기계학습 - 만능 함수 제조기</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 뉴론과 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사람은 사물들을 빨리 인식하는데 컴퓨터는 그렇게 할 수 없다는 것을 과학자들은 이미 오래 전부터 알고 있었습니다. 그래서 과학자들은 사람의 뇌는 어떻게 그렇게 빨리 판단(계산)을 할 수 있는지 연구했습니다. \n",
    "\n",
    "사람의 뇌는 약 850억개의 뉴론$^{neuron}$ 즉 뇌세포로 구성되어 있다고 합니다. 2015년 호주에서 유레카 상을 수상한 이 멋진 사진을 보십시오.\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/in search of memory_big.jpg?raw=true\" width=\"400\">\n",
    "<center>그림 5: 뉴론과 신경망 </center>\n",
    "<center>출처:[Australian Museum](https://australianmuseum.net.au/image/in-search-of-memory-eureka-prizes), 2015, Victor Anggono </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴론들이 서로 연결된 망을 신경망$^{neural \\ network}$이라고 합니다. 생물학적 뇌의 기본 단위인 뉴론들이 망$^{network}$으로 연결되어 서로 신호를 전달하면서 필요한 연산을 합니다. 뉴론을 서로 연결하는 시냅스의 수는 100조나 된다고 합니다. 그러니까 요즘 아무리 컴퓨터 기능이 뛰어나도, 병렬로 연결할지라도, 인간 한 사람의 두뇌에서 일어나는 신경망의 연산을 따라갈 수 없는 것입니다.\n",
    "\n",
    "- [In Search of Memory (Eureka Prizes)](https://australianmuseum.net.au/image/in-search-of-memory-eureka-prizes)\n",
    "- [The neurocienteist on call](http://www.suzanaherculanohouzel.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 뉴론의 임계값\n",
    "과학자들은 관찰을 통해 뉴론이 일종의 작은 하나의 연산자와 같다는 사실을 알아냈습니다. 뉴론은 입력 신호에 대해 즉시 반응하지는 않지만 출력을 내놓을 만큼 입력이 커질 때까지, 즉 임계값$^{threshold}$에 도달할 때까지 입력을 축적합니다.  예를 들면, 컵에 담긴 물이 처음으로 컵을 가득 채울 때까지는 흘러 넘치지 않는 것과 같습니다. 뉴론이 매우 작은 소리 신호가 아닌 아주 강한 신호 즉 어떤 임계값이 넘는 소리만을 전달한다고 이해하면 될 것입니다. \n",
    "\n",
    "### 2.2 뉴론의 입력과 출력\n",
    "과학자들이 발견한 또 다른 중요한 사실은 한 뉴런에 들어오는 신호 즉 입력은 다수이고 출력은 하나라는 것입니다. 둘째 사실은 여러 뉴론으로부터 전달되어 온 신호들은 합산되어 출력된다는 것이다. 합산된 값이 어떤 설정값 즉 임계값 이상이면 출력 신호가 있고, 이하이면 출력 신호가 없었습니다. \n",
    "\n",
    "### 2.3 인공뉴론과 인공신경망\n",
    "또한 인간의 생물학적 뉴론 하나가 아닌 다수가 연결되어 의미 있는 더 복잡한 작업을 할 수 있었습니다. 그래서, 과학자들은 뉴론과 신경망을 모델로 삼아, 단순한 계산을 하는 __인공뉴론$^{artificial \\ neuron}$__ 을 만들고, 여러 개의 인공뉴론들을 서로 연결한 __인공신경망$^{artificial \\ neural \\ network}$__ 을 만들어서 계산해보니 예전에 할 수 없었던 계산들을 할 수 있었습니다. \n",
    "\n",
    "다음은 두 개의 생물학적 뉴론과 하나의 인공 뉴론을 수학적 함수로 표현하여 모델링한 것입니다. 수상돌기는 입력 신호를 받고, 축색돌기는 신호를 출력합니다. 뉴론은 시냅스로 연결 되어 있어 시냅스에서 신호의 강약이 조정이 됩니다. 우리의 기억과 학습은 시냅스에 저장이 됩니다. \n",
    "\n",
    "지금까지 우리가 이야기한대로 과학자들이 이러한 생물학적 뉴론과 신경망에서 영감을 받아, 여러 입력을 받아 연산을 한 후에 어떤 값을 출력하는 함수로 뉴론을 모델링을 하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/neuron.png?raw=true\" width=\"400\"> </td> \n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/neuron_model.png?raw=true\" width=\"400\"/></td> \n",
    "</tr></table>\n",
    "<center>그림 6: 뉴론과 인공뉴론의 모델링</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 반복해서 말씀드렸듯이 기계학습을 통해서 우리가 구하고자 하는 것은 입력과 출력의 관계를 함수로 표현하는 것입니다. 전통적인 프로그램은 결국 프로그래머가 함수의 정확한 역할을 정의하고 코딩을 하고, 컴퓨터는 이 함수를 실행하기만 하면 되는 것이었습니다. 컴퓨터는 프로그래머가 지정한 것 이상의 일을 할 수 없었지요. \n",
    "\n",
    "다음 그림을 보면, 전통적인 프로그램이 아니라 우리는 인공신경망을 설계하고, 학습자료를 컴퓨터에게 넘겨 주면 컴퓨터가 기계학습을 하여 __\"꿈의 함수\"__를 만들어 냅니다. 프로그래머는 고양이 얼굴이 어떻게 생겼는지 귀가 큰지 작은지 특징을 코딩을 하는 것이 아니라 인공신경망을 설계하고, 학습자료를 제공하면 됩니다. 고양이를 구별해내고, 바둑 돌을 놓을 위치를 계산하는 함수는 컴퓨터가 찾아낼 것입니다.  \n",
    "\n",
    "그래서, 우리도 이제 인공신경망으로 함수들을 구현할 것입니다. 기존에 사용해왔던 수학적 표현이 아니라 뉴론들이 연결된 인공신경망을 학습시킬 것입니다. 다음 그림은 여러분이 궁극적으로 설계하고 구현할 인공신경망을 좀 간단히 그려 놓은 것입니다. 우리는 실제로 좀 더 복잡한 인공신경망을 만들어 손으로 쓴 숫자들을 구별하는 코딩을 해볼 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/google_cat.jpg?raw=true\" width=\"400\"> </td> \n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/MNIST-NN1.png?raw=true\" width=\"400\"/></td> \n",
    "</tr></table>\n",
    "<center>그림 7: 인공신경망(좌:이미지 분류, 우:MNIST 데이터셋)</center>\n",
    "<cener> 출처(좌): [Building high-level features using large scale unsupervised learning](https://arxiv.org/abs/1112.6209), 2012, Andrew Ng </center> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 불린 논리 함수 \n",
    "\n",
    "천리길도 한 걸음부터라는 속담이 있죠?\n",
    "\n",
    "인공신경망이 아니라 첫 인공뉴론을 만들어 간단한 인공뉴론 컴퓨팅부터 시작하고자 합니다. 아주 간단한 뉴론부터 시작하겠습니다. \n",
    "\n",
    "인공뉴론을 만든다는 것은 무슨 말이죠?  함수로 같은 기능을 만들면 되는 것입니다. 불린$^{Boolean}$ 논리 함수를 인공 뉴론으로 구현해보고자 합니다. 조지 불${George Boole}은 수학자이자 철학자였으며, 그의 이름은 AND 또는 OR과 같은 간단한 함수와 관련되어 있습니다.\n",
    "\n",
    "\n",
    "불린 논리 함수의 AND와 OR 함수의 예들 들면 다음과 같습니다.\n",
    "\n",
    "> 만약 \"바나나를 먹고 아직 배가 고프다면 망고를 먹을 수 있습니다\"라고 말한다면, 불린 AND 함수를 사용하는 것입니다. 불린 AND은 두 조건이 모두 참이어야 참이 될 수 있습니다. 둘 중 하나만 참이라면 참이 될 수 없습니다. 따라서 배가 고프지만 바나나를 먹지 않았다면, 망고를 먹을 수 없습니다.\n",
    "\n",
    "> 마찬가지로, \"주말이거나 공휴일이라면 공원에서 놀 수 있습니다\"라고 말한다면, 불린 OR 함수를 사용하는 것입니다. 불린 OR은 어떤 조건이라도 참이거나 모든 조건이 참이라면 참이 될 수 있습니다. 따라서 주말이 아니지만 공휴일이었다면 공원에서 놀 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수는 어떤 입력을 받아, 작업을 해서, 정답을 출력하는 기계로 볼 수 있습니다. 불린 논리 함수는 다음 그림과 같이 보통 하나 혹은 두 개의 입력을 받아 하나의 정답을 출력합니다. 예를 들면, 입력을 받은 __SVM__$^{Support Vector Machine}$이 논리 함수를 사용하여 계산하고 그 결과를 출력 할 수 있습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/simple_node2.png?raw=true\" width=\"300\">\n",
    "<center>그림 8: 논리함수와 SVM</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 논리 함수는 다음과 같이 두 개의 입력 신호를 받은 인공 뉴런$^{Neuron}$ 의 간단한 모델이라고 간주할 수 있습니다.   이런 인공 뉴런을 퍼셉트론$^{Perceptron}$ 이라고 부르기도 합니다.  \n",
    "\n",
    "\n",
    "여기서 $x_1$과 $x_2$ 는 입력이며, $y$는 출력, $w_1$과 $w_2$는 가중치$^{weight}$를 뜻합니다.   그림의 원은 뉴런 혹은 노드라고 부릅니다. 좀 더 자세한 사항은 다음 장에서 다룰 것입니다. 입력이 뉴런으로 보내질 때 각각 고유한 가중치가 곱해지고, 입력된 신호들의 총합이 정해진 값 즉 임계값$^{Threshold}$ $\\theta$(쎄타)를 넘어설 때만 출력을 합니다. 출력을 하는 뉴런(노드)은 활성화되었다고 말합니다. 이러한 개념을 수식을 표현하면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  y =\\begin{cases}\n",
    "   0 & \\text{$if \\ (w_1x_1 + w_2x_2) \\leq \\theta $} \\\\\n",
    "   1 & \\text{$otherwise.$}\n",
    "  \\end{cases}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 간단한 하나의 뉴런이 여러 개 연결되어 망$^{Network}$을 이루어 인공 신경망을 이루게 됩니다. 물론 입력이 상당히 많을 수 있으며, 중요한 입력 신호일수록 가중치가 높아집니다. \n",
    "컴퓨터는 대개 참$^{True}$ 을 숫자 1로, 거짓$^{False}$ 을 숫자 0으로 표현합니다. 다음 표는 간결한 표기법을 사용하여 입력 A와 B의 모든 조합에 대하여 논리 OR, AND, NAND 그리고 XOR 함수의 출력을 보여주는데, 이러한 표를 진리표$^{Truth Table}$ 이라고 합니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/truthtable.png?raw=true\" width=\"400\">\n",
    "<center>그림 9: 진리표</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1$와 $x_2$ 모두 참일 때만 AND 함수가 참이 된다는 것을 분명하게 알 수 있을 것입니다. 마찬가지로, 입력 $x_1$ 또는$x_2$ 중 어떤 것이 참일 때 OR 함수가 참이 된다는 것을 알 수 있을 것입니다.  NAND는 Not AND를 의미하며, 따라서 그 출력은 AND연산자의 출력의 반대입니다. \n",
    "\n",
    "불린 논리 함수는 컴퓨터 과학에서 아주 중요하며, 초기의 컴퓨터는 이러한 논리 함수로 수행되는 작은 전자 회로에서부터 만들어졌습니다. 연산도 간단한 불린 논리 함수였던 회로의 조합을 사용하여 수행되었습니다.\n",
    "\n",
    "논리 함수에 들어가는 두 입력 $x_1$와 $x_2$을 그래프에서 좌표로 표현한 다음 그림을 살펴보세요. 이 그림은 값이 1으로 두 조건 모두 참일 때만 출력도 참이 된다는 것을 보여주며 검정색으로 나타냅니다. 거짓 출력값은 빨간 점으로 나타냅니다.\n",
    "\n",
    "<table><tr>\n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/and_classifier.png?raw=true\" width=\"400\"> </td> \n",
    "    <td><img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/or_classifier.png?raw=true\" width=\"400\"/></td> \n",
    "</tr></table>\n",
    "\n",
    "<center>그림 10: AND/OR 논리 연산을 다루는 판별식</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분은 빨간 점 영역과 검은 점 영역을 나누는 선을 볼 수 있는데, 이렇게 자료를 구별할 수 있는 식을 __판별식__$^{Decision \\ boundary}$이라고 부릅니다. 이런 판별식을 구하는 것을 선형으로 나타날 때, 이것을 __선형 분류기__$^{Linear \\ classifier}$라고 부릅니다. \n",
    "\n",
    "이 판별식은 선형 함수로 나타나지만, 곡선일 수 있으며, 다차원에서는 평면이나 입체 혹은 우리가 그림으로는 표현할 수 없는 다차원 공간에서의 어떤 경계를 나타냅니다.  우리는 이전과 같이 숫자 작업은 하지 않을 것입니다. 그 이유는 이 예시에서도 근본적으로 다르지 않기 때문입니다.  사실, 이 나누는 선에는 많은 편차가 있습니다. 하지만 요점은 $y=a∙x+b$의 형태를 가진 단순한 판별식은 불린 AND 함수를 학습하는 것이 가능하다는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND 연산자를 인공 뉴런으로 표현하려면 어떻게 하면 될까요?  진리표대로 입력이 있을 때, 해당되는 출력을 낼 수 있도록 수식대로 $w_1$, $w_2$, $\\theta$ 값을 정하면 됩니다.  다만, 이 조건을 만족하는 판별식이 무한히 많으므로, 적절한 값을 정하는 것이 중요합니다. \n",
    "\n",
    "예를 들면, $(w_1, w_2, \\theta)$가 $(0.5, 0.5, 0.75)$, 혹은 $(0.5, 0.5, 0.8)$, 혹은 $(1.0, 1.0, 1.0)$ 일 때 모두 AND논리 연산을 만족합니다. 즉 매개 변수 $x_1$, $x_2$  모두가 1일 때만 모든 입력 값의 합이 주어진 임계값보다 크므로 출력이 1이 됩니다.    \n",
    "\n",
    "이러한 논리 연산은 아래와 같은 코드로 점검할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x1, x2) :\n",
    "    w1, w2, theta = 0.5, 0.5, 0.75\n",
    "    y = x1 * w1 + x2 * w2 \n",
    "    if y <= theta:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 비슷하게 그래프로 그린 불린 OR 함수를 살펴보세요. \n",
    "\n",
    "이번에는 $(0, 0)$ 점만 빨간 점입니다. 그 이유는 이것의 입력 $x_1$와 $x_2$ 모두 거짓이기 때문입니다.  다른 조합들은 적어도 $x_1$와 $x_2$ 중 하나는 참이기 때문에 출력이 참이 됩니다. 이 그림의 장점은 선형 분류기가 불린 OR 함수도 학습할 수 있다는 것을 명백히 보여준다는 것입니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배타적 논리합$^{eXclusive OR}$을 간단히 줄여서 XOR라 하는 또 다른 불린 함수도 있습니다. 이것은 입력 $x_1$ 또는 $x_2$ 중 하나만 참일 때 출력이 참이 됩니다. 즉, 두 입력 모두 거짓이거나 모두 참일 때에는, 출력이 거짓이 됩니다. 이제 이 논리 함수의 결과를 색깔로 출력하고 이를 구분하여 그린 그림에 판별식을 그려 넣어볼까요?\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/XORClassifier1.png?raw=true\" width=\"300\">\n",
    "<center>그림 11: 배타적 논리합(XOR) 연산</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "난제이군요! \n",
    "\n",
    "하나의 판별식으로는 빨간 점과 검은 점 영역을 나눌 수 없을 것 같습니다. 사실, 불린 XOR에 대한 빨간 점 영역과 검은 점 영역을 성공적으로 나누는 하나의 선형 판별식만 갖는 것은 불가능합니다. 즉, XOR 함수로 결정되는 학습 자료로 나타냈을 때 하나의 단순한 판별식만으로는 불린 XOR을 학습할 수 없습니다.  \n",
    "물론, 결정 경계선이 비선형$^{non-linear}$이면 다음 그림과 같이 가능하겠죠? \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/XORClassifier4.png?raw=true\" width=\"300\">\n",
    "<center>그림 12: 비선형 판별식의 예시</center>\n",
    "\n",
    "우리는 단순한 선형 분류기의 주요 한계를 설명했습니다. 이 판별식은 기본적인 문제를 직선으로 분류할 수 없을 경우에는 유용하지 않습니다.  우리는 기본적인 문제를 선형으로 분류할 수 없어 하나의 판별식으로는 도움이 될 수 없는 여러 문제에서도 유용한 신경망을 만들고자 합니다.\n",
    "따라서 우리는 새로운 분류기가 필요합니다. 어떤 분류기를 만들면 가능할까요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금만 생각하면 아주 간단하게 할 수 있습니다. 다음의 그림처럼 다수의 판별식들을 사용하는 것입니다. 즉 두 개의 직선으로 서로 다른 영역을 나누는 개선 방법을 제안합니다. 이것은 신경망의 중심 개념입니다. 여러분은 특이한 모양의 영역을 분류할 때에도 여러 판별식으로 나눌 수 있다는 것을 이미 생각했을 것입니다.\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/XORClassifier5.png?raw=true\" width=\"300\">\n",
    "<center>그림 13: XOR 논리 연산을 다루는 판별식</center>\n",
    "\n",
    "우리가 곧 다루게 될 신경망에서는 XOR문제도 여러 층을 신경망을 사용하여 해결할 수 있겠지만, SVM 에서는 차원$^{Dimension}$을 늘리는 방법으로 해결할 수 있습니다. 원래 2차원 공간에서의 XOR문제를 다음의 매핑 함수 ∅(x)를 통해 3차원으로 확장시키면 다음의 표와 같습니다. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\phi(x)} = \\begin{bmatrix}\n",
    "x_1^2\\\\\\sqrt2x_1x_2\\\\x_2^2\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/xor_mapping1.png?raw=true\" width=\"400\">\n",
    "<center>그림 14: XOR 논리 연산을 SVM에서 다루는 3차원 매핑</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 과정을 시각적으로 표현하면 다음의 그림과 같습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/xor_mapping2.png?raw=true\" width=\"400\">\n",
    "<center>그림 15: XOR 논리 연산을 SVM에서 다루는 3차원 매핑의 시각화</center>\n",
    "\n",
    "\n",
    "이것을 정리하면, 하나의 단순한 선형 분류기로 모든 자료들을 분류할 수는 없습니다. 예를 들어 논리 XOR 연산자로 결정되는 자료들이 여기에 해당합니다. 하지만 해결 방법은 있습니다. 다수의 선형 판별식을 사용하여 하나의 판별식으로 분류할 수 없는 자료를 분류해낼 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 가중치와 편향\n",
    "\n",
    "앞에서 구현한 AND 연산자를 인공 뉴런은 간단하고 쉽지만, 앞으로 우리가 다루어야 할 신경망은 훨씬 더 복잡해질 것입니다. 한 뉴론에 대하여 앞에서 아래와 같이 정의한 수식을  \n",
    "\n",
    "\\begin{equation}\n",
    "  y =\\begin{cases}\n",
    "   0 & \\text{$if \\ (w_1x_1 + w_2x_2) \\leq \\theta $} \\\\\n",
    "   1 & \\text{$otherwise.$}\n",
    "  \\end{cases}\n",
    "\\end{equation} \n",
    "\n",
    "아래와 같이 조금 다르게 표현하고자 합니다. \n",
    "\n",
    "\\begin{equation}\n",
    "  y =\\begin{cases}\n",
    "   0 & \\text{$if \\ (b + w_1x_1 + w_2x_2) \\leq 0 $} \\\\\n",
    "   1 & \\text{$otherwise.$}\n",
    "  \\end{cases}\n",
    "\\end{equation} \n",
    "\n",
    "두 식은 임계값 $\\theta$를 $b$ 로 다르게 표현한 것뿐입니다. 여기서 $b$를 편향$^{bias}$라고 합니다.  그러면, 이제, 임계값은 0가 되므로, 입력에 가중치를 곱하고 편향을 더 한 값이 0가 넘으면 1을 출력하고, 아니면 0를 출력합니다.  편향을 명시한 인공 뉴런을 다음과 같이 나타낼 수 있습니다. \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/simple_node3.png?raw=true\" width=\"400\">\n",
    "<center>그림 16: 편향을 표기한 인공 뉴론</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제: 인공 뉴론 예제\n",
    "\n",
    "두 개의 입력과 편향이 각각 $x_1 = 0$, $x_2 = 1$, $b = -0.75$인 뉴론의 출력을 구하는 코딩은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([0, 1])\n",
    "w = np.array([0.5, 0.5])\n",
    "b = -0.75\n",
    "y = np.sum(w*x) + b         # y = np.dot(w, x) + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이에서 두 배열의 원소의 수가 같다면 배열끼리의 곱셈은 각각 원소끼리 곱합니다.  그래서 $w * x$는 인덱스가 같은 원소끼리 `[0, 1] * [0.5, 0.5]` 곱하면, 결과는 `[0, 0.5]` 이며, `np.sum()` 메소드$^{method}$는 입력한 배열에 있는 모든 원소의 합 `(0 + 0.5)`을 구하여 반환합니다. 이 값에 편향을 더하면 위의 수식과 동일한 것이며, 이것이 곧 출력 `y`의 값입니다.  이 예제에서 `b = 0.75`인 이유는 $\\theta$는 $–b$ 로 치환돼야 하기 때문입니다.   이러한 실험과 확인을 통해 다음과 같이 AND 연산자 뉴런을 구현합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoyCoding: AND 뉴론 만들기(1)\n",
    "인공 뉴론을 활용하여 입력 (x1, x2)를 인자로 받은 AND()함수를 코딩하십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])        # input\n",
    "    w = np.array([0.5, 0.5])      # weights\n",
    "    b = -0.75                     # bias\n",
    "    y = np.sum(w * x) + b\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 과정에서 우리가 한 가지 관찰해야 할 것은 편중(b)은 가중치$(w_1, w_2)$와 다른 기능을 한다는 것입니다.  가중치는 각 입력 신호가 결과에 주는 영향을 조절하는 매개변수이며, 편향은 뉴런이 얼마나 쉽게 활성화 하느냐를 조정하는 매개변수입니다. 예를 $b = -0.2$이면, 각 입력에 가중치를 곱한 값들의 총합이 $0.2$를 초과할 때 뉴런이 활성화(1을 출력)합니다. 이렇게 편향이 값은 뉴런이 얼마나 쉽게 활성화되는지 결정합니다.  그러나, 종종 모든 입력 자료들을 표준화$^{normalize}$하여, 편향$b = 0$가 되도록 조정하는 경우도 있다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoyCoding: AND 뉴론 만들기(2)\n",
    "위의 AND()함수 코딩에서 편향(bias)을 $w$, $x$에 포함하여, 한번에 계산하는 방법으로 코딩하십시오.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def AND(x1, x2):\n",
    "    x = np.array([1, x1, x2])  \n",
    "    w = np.array([-0.75, 0.5, 0.5])      # bias + weights\n",
    "    y = np.sum(w * x)                     # y = np.dot(w, x)\n",
    "    if y > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoyCoding: AND 뉴론 만들기(3)\n",
    "위의 AND()함수 코딩에서 마지막 세 줄을 삼항 연산자$^{ternary \\ operator}$ 사용하여 한 줄로 코딩하십시오.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    x = np.array([1, x1, x2])  \n",
    "    w = np.array([-0.75, 0.5, 0.5])      # bias + weights\n",
    "    y = np.dot(w, x)                     # y = np.dot(w, x)\n",
    "    return 1 if y > 0 else 0           # using ternary operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR 논리 함수 구현하기\n",
    "\n",
    "단순한 인공 뉴런으로는 XOR 연산자를 구현할 수 없었습니다.  앞으로 우리가 배울 인공 신경망에서는 뉴런을 여러 층으로 쌓아서 그러한 문제를 해결할 수 있게 됩니다.  우리가 지금 바로 다층 신경망$^{Multi-layer \\ neural \\ network}$ 문제에 바로 도전하기 보다는 워밍업$^{Warming-up}$ 문제로 XOR 연산자를 다른 연산자(AND, NAND, OR)들을 조합하여 구현하는 문제에 먼저 도전합니다.\n",
    "\n",
    "집적회로를 이루고 있는 연산자들(AND, NAND, OR)의 기호는 다음과 같습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/gates.png?raw=true\" width=\"300\">\n",
    "<center>그림 17: AND, NAND, OR 연산자 기호</center>\n",
    "\n",
    "XOR연산자를 AND, NAND, OR 연산자를 조합하여 구현할 수 있습니다.  아래 그림에서 빈칸에 AND, NAND, OR 연산자를 대입하여 완성할 수 있습니다.   \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/xor_logic1.png?raw=true\" width=\"300\">\n",
    "<center>그림 18: AND, NAND, OR 연산자를 조합하여 XOR 연산자 만들기 </center>\n",
    "\n",
    "다음과 같은 XOR진리표를 보면 더 용이하게 XOR연산자를 만들 수 있을 것입니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/xor_logic2.png?raw=true\" width=\"300\">\n",
    "<center>그림 19: AND, NAND, OR 연산자를 조합하여 XOR 연산자 만들기 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoyCoding: XOR 뉴론 만들기(1)\n",
    "위의 그림 18과 19를 참조하여, XOR를 구현하십시오. 힌트: NAND, OR, AND의 조합을 사용하면 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND(x1, x2):\n",
    "    return int(not AND(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND(x1, x2):\n",
    "    return (not AND(x1, x2)) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(NAND(0, 0))\n",
    "print(NAND(0, 1))\n",
    "print(NAND(1, 0))\n",
    "print(NAND(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(x1, x2):\n",
    "    x = np.array([1, x1, x2])  \n",
    "    w = np.array([-0.45, 0.5, 0.5])      # bias + weights\n",
    "    y = np.dot(w, x)                     # y = np.dot(w, x)\n",
    "    return 1 if y > 0 else 0            # using ternary operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(OR(0, 0))\n",
    "print(OR(0, 1))\n",
    "print(OR(1, 0))\n",
    "print(OR(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    h1 = NAND(x1, x2)\n",
    "    h2 = OR(x1, x2)\n",
    "    return AND(h1, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(XOR(0, 0))\n",
    "print(XOR(0, 1))\n",
    "print(XOR(1, 0))\n",
    "print(XOR(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JoyCoding: NAND 뉴론 만들기(2)\n",
    "여러 개의 NAND만을 사용해서 XOR를 구현할 수 있습니다. 인터넷 자료를 자료를 참조하여 구현해 보십시오.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XORNAND(x1, x2):   # XOR using NAND only\n",
    "    None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JoyCoding: \n",
    "NumPy를 사용하여, NAND, OR, XOR연산자를 구현하여 logic.py 파일에 저장하고, 다음과 같이 jupyter notebook에서 실행하여 연산자들을 점검하십시오. \n",
    "\n",
    "단, XOR를 AND, NAND, OR를 사용해서 구현하고, 또한 NAND 함수만을 사용해서 구현하여 테스트하십시오. 셀매직 %%writefile my_file_name을 사용하면, 셀의 코드를 파일에 저장할 수 있습니다. 셀매직은 셀의 첫줄에 위치해야 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile logic.py\n",
    "def AND(x1, x2):\n",
    "    None\n",
    "    return None\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    return None\n",
    "    \n",
    "def OR(x1, x2):\n",
    "    None\n",
    "    return None\n",
    "    \n",
    "def XOR(x1, x2):\n",
    "    None\n",
    "    return None\n",
    "\n",
    "def XORNAND(x1, x2):\n",
    "    None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "NAND\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "OR\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "XOR\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "XOR_NAND\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#%run logic.py\n",
    "print(\"AND\")\n",
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))\n",
    "print(\"NAND\")\n",
    "print(NAND(0, 0))\n",
    "print(NAND(0, 1))\n",
    "print(NAND(1, 0))\n",
    "print(NAND(1, 1))\n",
    "print(\"OR\")\n",
    "print(OR(0, 0))\n",
    "print(OR(0, 1))\n",
    "print(OR(1, 0))\n",
    "print(OR(1, 1))\n",
    "print(\"XOR\")\n",
    "print(XOR(0, 0))\n",
    "print(XOR(0, 1))\n",
    "print(XOR(1, 0))\n",
    "print(XOR(1, 1))\n",
    "print(\"XORNAND\")\n",
    "print(XORN(0, 0))\n",
    "print(XORN(0, 1))\n",
    "print(XORN(1, 0))\n",
    "print(XORN(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 논리 함수를 실행하면 앞에서 다루었던 진리표와 같이 출력이 되어야 합니다.  만약에 여러분의 Python 코드가 진리표와 같지 않은 결과를 출력한다면, 어디가 틀렸는지 다시 검토해 보길 바랍니다.  이러한 것을 디버깅$^{debugging}$이라고 합니다.  어떤 문제를 해결하기 위하여 프로그래밍할 때는 한번 프로그램이 완성될 것이라고 기대하지 마십시오.  프로그램은 항상 고쳐야 할 부분도 있고 개선될 부분도 있다는 것을 전제로 하십시오.  디버깅도 기쁨으로 하면 좋습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고자료\n",
    "- CS231n Convolutional Neural Networks for Visual Recognition, [Python Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/), Stanford University\n",
    "- [Python For Data Science Cheat Sheet NumPy Basics](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf), DataCamp\n",
    "- Python Numpy Tutorial - http://cs231n.github.io/\n",
    "- 김태완 블로그: [파이썬 데이터 사이언스 Cheat Sheet](http://taewan.kim/post/numpy_cheat_sheet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정리\n",
    "- 함수와 뉴론의 이해\n",
    "- 인공뉴론과 인공신경망의 이해  \n",
    "- 첫 인공뉴론의 구현\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
