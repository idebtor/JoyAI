{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fear of the LORD is the beginning of knowledge, but fools despise wisdom and discipline. Proverbs 1:7\n",
    "\n",
    "-------\n",
    "\n",
    "# Welcome to \"AI for All\"\n",
    "\n",
    "Lecture Notes by idebtor@gmail.com, Handong Global University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 4.  손실함수와 경사하강법(Gradient Descent)\n",
    "\n",
    ":본 단원은 참고문헌 (3)에서 발췌한 것입니다. \n",
    "\n",
    "--------------\n",
    "경사 하강법에 사용한 손실 함수가 어떻게 사용된 것인지 알아봅니다. 경사 하강법은 정의된 손실 함수의 값이 최소가 되는 지점을 찾아가는 방법입니다. 여기서 손실 함수란 예측 값과 타깃 값의 차이를 함수로 정의한 것을 말합니다. 지금까지 우리가 사용한 방법인 '오차를 변화율에 곱하여 가중치와 편향 조정하기'는 제곱 오차라는 손실 함수를 미분한 것과 같습니다. 여기서는 '손실 함수'으로부터 경사 하강법을 접근하는 방법을 시도합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 손실 함수의 모든 것\n",
    "\n",
    "제곱 오차(squared error)는 타깃(실제)값과 예측값을 뺀 다음 제곱한 것입니다. 제곱 오차를 수식으로 나타내면 다음과 같습니다. \n",
    "\n",
    "\\begin{align}\n",
    "SE = (y - \\hat{y})^2  \\tag{1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 제곱 오차가 최소가 되면 산점도 그래프를 가장 잘 표현한 직선이 그려집니다. 즉, 제곱 오차의 최솟값을 찾는 방법을 알면 모델을 쉽게 만들 수 있습니다. 다음은 제곱 오차와 직선의 관계를 나타낸 그래프입니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-diabetes8.png?raw=true\" width=\"400\">\n",
    "<center>그림 1: 제곱 오차(SE)와 선형 회귀(직선)의 관계 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제곱 오차 함수의 최솟값을 알아내려면 기울기에 따라 함수의 값이 낮은 쪽으로 이동해야 합니다. 기울기를 구하려면 제곱 오차를 가중치나 편향에 대해 미분하면 됩니다.  다행히 제곱 오차는 가중치나 편향에 대해 미분이 가능합니다. 그러면 먼저 가중치에 대하여 제곱 오차를 미분해 보겠습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 가중치에 대하여 제곱 오차 미분하기\n",
    "\n",
    "다음 식은 제곱 오차를 가중치($w$)에 대하여 편미분한 것입니다. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{SE}}{\\partial{w}}  \n",
    "&= \\frac{\\partial}{\\partial{w}} (y - \\hat{y})^2   \\qquad{\\because{ f(g(x))' = f'(g(x))g'(x) } } \\\\\n",
    "&= 2(y - \\hat{y}) \\frac{\\partial}{\\partial{w}} (y - \\hat{y}) \\qquad{\\because{\\text{y is a constant}} } \\\\\n",
    "&= 2(y - \\hat{y}) (- \\frac{\\partial}{\\partial{w}} \\hat{y}) \\\\\n",
    "&= 2(y - \\hat{y}) (- \\frac{\\partial}{\\partial{w}} (wx + b)) \\qquad{\\because{\\text{w, b are constants}} } \\\\\n",
    "&= 2(y - \\hat{y}) (- x) \\\\\n",
    "&= -2(y - \\hat{y}) x \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편미분이란 미분의 대상 변수($w$)를 제외한 다른 변수($x, b$ 등)를 상수로 취급하여 미분한 것입니다. 이 때 $y$는 준비된 타깃 데이터이므로 $w$의 함수가 아니고 $\\hat{y}$은 $w$의 함수($\\hat{y} = wx + b$)입니다. \n",
    "\n",
    "따라서 $\\hat{y}$을 $w$에 대해 미분하면 상수항 $b$는 사라지고 $x$만 남습니다. 결국 제곱 오차를 가중치($w$)에 대해 미분한 결과는 다음과 같습니다. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{SE}}{\\partial{w}} = -2(y - \\hat{y}) x \\tag{2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최기에 제곱 오차 공식을 $(y - \\hat{y})^2$가 아니라 $\\frac{1}{2}(y - \\hat{y})^2$로 정의했다면 2와 $\\frac{1}{2}$이 서로 약분되어 조금 더 깔끔하게 $-(y-\\hat{y})x$ 로 표현할 수 있었을 것입니다. 그래서, 보통은 제곱 오차 공식을 2로 나눈 함수를 편미분합니다. 여기에서도 아래와 같이 가중치에 대한 제곱 오차의 변화율은 $-(y-\\hat{y})x$ 를 사용하도록 하겠습니다. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{SE}}{\\partial{w}} = -(y - \\hat{y}) x \\tag{3}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 미분한 오차 함수로 가중치 조정하기\n",
    "\n",
    "가중치에 대한 제곱 오차의 변화율을 구했습니다. 이제 기존의 가중치를 조정하기 위하여, 앞에서 가중치를 조정할 때 변화율을 더했던 것과 마찬가지로 가중치를 조정합니다. 여기서는 $w$에서 변화율을 뺍니다. $w$에서 변화율을 더하지 않고 빼는 이유는 손실 함수의 낮은 쪽으로 이동하고 싶기 때문입니다. \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "w_{new} &= w - \\frac{\\partial{SE}}{\\partial{w}}  \\\\\n",
    "        &= w + (y - \\hat{y}) x \\tag{4}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 식을 어디서 본 것 같지 않나요? \n",
    "\n",
    "앞에서 오차 역전파를 알아보면 작성한 코드에 이와 같은 식이 있었습니다. 오차 역전파를 알아보며 적용했던 수식(`w + w_rate * err`)은 사실 제공 오차를 미분했던 것과 같았던 것입니다. 아래 코드를 살펴보십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 편향에 대하여 제곱 오차 미분하기\n",
    "\n",
    "편향에 대하여 제곱 오차를 미분할 때는 처음부터 $\\frac{1}{2}$를 곱한 제곱 오차 공식을 사용합니다. 유도식은 다음과 같습니다. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{SE}}{\\partial{b}}  \n",
    "&= \\frac{\\partial}{\\partial{b}} \\frac{1}{2}(y - \\hat{y})^2   \\qquad{\\because{ f(g(x))' = f'(g(x))g'(x) } } \\\\\n",
    "&= (y - \\hat{y}) \\frac{\\partial}{\\partial{b}} (y - \\hat{y}) \\qquad{\\because{\\text{y is a constant}} } \\\\\n",
    "&= (y - \\hat{y}) (- \\frac{\\partial}{\\partial{b}} \\hat{y}) \\\\\n",
    "&= 2(y - \\hat{y}) (- \\frac{\\partial}{\\partial{b}} (wx + b)) \\qquad{\\because{\\text{w, x are constants}} } \\\\\n",
    "&= (y - \\hat{y}) (-1) \\\\\n",
    "&= -(y - \\hat{y}) 1 \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미분 과정은 앞에 했던 $w$에 대한 편미분 과정과 매우 비슷합니다. 가중치에서 변화율을 뺐던 이유와 같은 이유로 편향에서 변화율을 뺍니다. \n",
    "\n",
    "\\begin{align}\n",
    "b_{new} &= b - \\frac{\\partial{SE}}{\\partial{b}}  \\\\\n",
    "        &= b + (y - \\hat{y})  \\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "이 식도 앞에서 작성한 코드와 정확히 일치합니다. 다음 코드를 참고하십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = None\n",
    "b = b + 1 * err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞으로는 손실 함수에 대해 일일이 변화율의 값을 계산하는 대신 편미분을 사용하여 변화율을 계산합니다. 그리고 변화율은 인공지능 분야에서 특별히 Gradient(그레디언트, 경사)라고 부릅니다. 앞으로는 변화율이란 용어 대신 Gradient를 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 상황에서는 `w`가 증가하면, `y_hat`은 감소합니다. 반대로 말하면, `w`가 감소하면, `y_hat`은 증가합니다. 이때 변화율이 음수인 점을 이용하면, 앞에서 한 대로 변화율을 더하는 방법으로 `y_hat`의 값을 증가시킬 수 있습니다. \n",
    "\n",
    "두 경우 모두 `w`에 `w_rate`를 더하면 되는 것입니다! 계산이 아주 쉬워진 것이죠. 즉, 가중치 `w`를 조정하는 방법은 두 경우 모두 `w + w_rate`입니다.  다음은 가중치를 조정하는 예입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 경사 하강법을 사용한 회귀 문제를 변화율을 직접 구하는 방식과 미분을 사용한 방식(손실 함수)으로 검증해 보았습니다. 다음에는 지금까지 배운 내용을 모두 정리하여 하나의 파이썬 클래스를 만들어 봅니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "\n",
    "1. 케라스 창시자에게 배우는 딥러닝, 프랑소와 숄레, 길벗\n",
    "1. 핸즈온 머신러닝, 오렐리앙 제롱, 한빛미디어\n",
    "1. 딥러닝 입문, 박해선, 이지스 퍼블리싱\n",
    "1. 파이썬으로 배우는 기계학습, 김영섭, K-MOOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
